# Sentiment Analysis of Content Created by chatGPT

Under the supervision of Professor Raphaël Khoury, this is my final project to obtain my bachelor's in computer science from the University of Québec in Outaouais.

## Objective

ChatGPT is writing more content. Ideally, chatGPT would use unbiased and factual language. This research seeks to find if the content created by chatGPT is positive, neutral, or negative. In particular, it seeks to find if chatGPT is biased towards certain subjects and if/how much the temperature parameter affects the language used by chatGPT. We used the chatGPT 4o-mini model and the chatGPT API to generate the data.

## Discussion

This research studied ChatGPT's behavior regarding content generation, specifically the generation of news articles based on instructions and data given in the form of bullet points. It cannot be confirmed that ChatGPT generates content with a political bias. It is observed that ChatGPT uses more positive language with left-leaning articles, though this does not necessarily mean that ChatGPT is biased towards the left. This could also reflect the fact that the original left-leaning articles passed on as data to ChatGPT use particularly negative language to describe the right and politicians like Trump and that ChatGPT uses more modest language to describe the right. The database of articles taken for this study is not adequate to arrive at a conclusion. There were not enough articles, especially left-leaning articles. The starting parameters for the articles are not ideal: The sentimental scores (a measure of how positive or negative the articles are) of the original articles are not equal between the left and the right. The size and subject of the original articles varied widely between the left and the right.

It is interesting to note that the sentimental score of the articles, original and generated, followed a normal distribution. This could indicate that events or themes covered in the articles tended to produce a diversity of emotions, from the negative to the positive, with a majority of the content concentrated and staying neutral, or lightly negative in the case of the articles examined during this study.

It is important to remark that ChatGPT uses more positive language. This can be due to many different reasons, like the fact that ChatGPT tends to add positive adjectives to describe certain statistics or that ChatGPT might use different words while writing in the first or third person.

ChatGPT does not reproduce the sarcasm from the original articles but tends to explicitly explain the underlying ideas and emotions of the human writer. If the original article employs sarcasm, like seen in the edge cases, ChatGPT can employ a language considered more negative by sentiment analysis algorithms, since sarcasm frequently employs positive words in a negative context, something that at least the algorithm used in this study, Afinn, could not identify.

In general, according to the Spearman test, ChatGPT generates articles whose objectivity tends to follow the tendance of original articles. This means that if the original article uses positive language, then the article generated by ChatGPT will also use positive language. The temperature parameter available in the API of ChatGPT (degree of liberty of expression) has a negligible effect concerning the sentimental score of the generated articles. However, it can be observed that ChatGPT tends to generate more words when the temperature parameter increases. In addition, ChatGPT has difficulty generating more than 1000 words in one prompt.

An improvement to this research would be to rewrite the calculation used for the averaging of the sentimental scores and give more weight to the articles that have more words, instead of treating every article as equal. This way, the articles with more words will be worth more, and the articles with fewer words will be worth less, thus reducing the influence of edge cases.

This study continues past research on ChatGPT, the objectivity of ChatGPT, and the bias of ChatGPT using a new method. This method consists of generating articles based on content in original articles, with the ChatGPT API, and then analyzing the sentimental scores with a sentiment analysis algorithm like Afinn, followed by an interpretation of the results through statistical methods. It would be interesting to continue this research by focusing on different themes and questions raised, for example, the influence of the temperature of ChatGPT on the size and content generated and the bias of ChatGPT with better, more uniform data.

I encourage you to take a look at the data and the generated articles yourself. Please don't hesitate to contact me if you have any questions.

**Please reference the report for details. It is in French.**
